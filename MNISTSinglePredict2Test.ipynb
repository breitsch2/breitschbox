{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNISTSinglePredict2Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+gC4MLOHagjfzr75rZQBf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxkleiner/maXbox4/blob/master/MNISTSinglePredict2Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LG1bU4qhq7b"
      },
      "source": [
        "# MNIST Single Multi Prediction\n",
        "For this tutor we’ll explore one of the classic machine learning datasets – hand written digits classification. We have set up a very simple SVC to classify the MNIST digits to make one single predict.\n",
        "First we load the libraries and the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfMRkbuMgvqn",
        "outputId": "709477f1-5f16-4051-8a67-25266b528ee7"
      },
      "source": [
        "#sign:max: MAXBOX8: 13/03/2021 07:46:37 \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# [height, weight, 8*8 pixels of digits 0..9]\n",
        "dimages = datasets.load_digits()\n",
        "print(type(dimages), len(dimages.data), 'samples')\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'sklearn.utils.Bunch'> 1797 samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubq_cnq1j5bA"
      },
      "source": [
        "The **dataset** **()** is available either for download from the UCI ML repository or via a Python library scikit-learn dataset. Then we setup the Support Vector Classifier with the training data X and the target y:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZjIuWF-kYGE",
        "outputId": "2114b25a-9cf3-4083-977a-2db43d8e8a22"
      },
      "source": [
        "sclf = SVC(gamma=0.001, C=100, kernel='linear')\n",
        "\n",
        "X= dimages.data[:-10]\n",
        "y= dimages.target[:-10]\n",
        "print('train set samples:',len(X))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train set samples: 1787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCKdhimKmKAC"
      },
      "source": [
        "Gamma is the learning rate and the higher the value of gamma the more precise the decision boundary would be. C (regularization) is the penalty of the fault tolerance. Having a larger C will lead to smaller values for the slack variables. This means that the number of support vectors will decrease. When you run the prediction, it will need to calculate the indicator function for each support vector. Now we train (fit) the samples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDPXPTMImUZP",
        "outputId": "018c9ef5-b52d-457d-dbb3-caf7cf217f82"
      },
      "source": [
        "sclf.fit(X,y)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzClaWdknfhO"
      },
      "source": [
        "In the last step we predict a specific digit from the test set (only the last 10 samples are unseen), means we pass an actual image and SVC makes the prediction of which digit belongs to the image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "YAcgQEaPoMjZ",
        "outputId": "0975dff0-e549-4c6c-c263-752678f40b63"
      },
      "source": [
        "testimage = -5\n",
        "\n",
        "s_prediction = sclf.predict([dimages.data[testimage]])\n",
        "print ('the image maybe belongs to ',s_prediction)\n",
        "plt.imshow(dimages.images[testimage], cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the image maybe belongs to  [9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMmWhujWo4oN"
      },
      "source": [
        "The same fit we try with a Random Forest Classifier to finish the first step of this lesson:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4JftkPNpCqE",
        "outputId": "99431a87-647c-48fd-d5c3-f71037ae538d"
      },
      "source": [
        "#RandomForestClassifier\n",
        "rfc_clf = RandomForestClassifier()\n",
        "rfc_clf.fit(X,y)\n",
        "rfc_prediction = rfc_clf.predict([dimages.data[testimage]])\n",
        "print ('predict with RFC ',rfc_prediction)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict with RFC  [9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9GwYWnL7RFI"
      },
      "source": [
        "There are many ways to improve this predict, including not using a vector classifier and go further with a neural classifier, but here’s a simple one to start what we do. Let’s just simplify our images by making them true black and white and stack an array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oEs4Xz37X4Z"
      },
      "source": [
        "# MNIST Multi Prediction \n",
        "![tvbt2_40.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVwI4jKV71RY"
      },
      "source": [
        "Now we split explicit data in train- and test-set. Splitting the given images in 80:20 ratio so that 80% image is available for training and 20 % image is available for testing. We consider the data as pixels and the target as labels.\n",
        "\n",
        "Convert and create the dataframe from datasets. We are using support vector machines for classification. Fit method trains the model and score will test it against the given test set and score.\n",
        "\n",
        "A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In other words, given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes new examples. In two dimensional space this hyperplane is a line dividing a plane in two parts where in each class lay in either side."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC-g6xG_8Cah",
        "outputId": "5f1aed72-2b80-4116-8c0a-b93ebf94b06f"
      },
      "source": [
        "#df = pd.DataFrame(data=dimages.data, columns=dimages.feature_names)\n",
        "df = pd.DataFrame(data=dimages.data)\n",
        "print(df.head(5))\n",
        "df['target'] = pd.Series(dimages.target)\n",
        "#df['pixels'] = dimages.data[:,1:64] #pd.Series(dimages.data[:,1:785])\n",
        "print(df['target'])\n",
        "print(df.shape) #print(df.info)\n",
        " \n",
        "pixels = df\n",
        "labels = df.target\n",
        "print('pixels ',pixels)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    0    1    2     3     4     5    6   ...   57   58    59    60    61   62   63\n",
            "0  0.0  0.0  5.0  13.0   9.0   1.0  0.0  ...  0.0  6.0  13.0  10.0   0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  12.0  13.0   5.0  0.0  ...  0.0  0.0  11.0  16.0  10.0  0.0  0.0\n",
            "2  0.0  0.0  0.0   4.0  15.0  12.0  0.0  ...  0.0  0.0   3.0  11.0  16.0  9.0  0.0\n",
            "3  0.0  0.0  7.0  15.0  13.0   1.0  0.0  ...  0.0  7.0  13.0  13.0   9.0  0.0  0.0\n",
            "4  0.0  0.0  0.0   1.0  11.0   0.0  0.0  ...  0.0  0.0   2.0  16.0   4.0  0.0  0.0\n",
            "\n",
            "[5 rows x 64 columns]\n",
            "0       0\n",
            "1       1\n",
            "2       2\n",
            "3       3\n",
            "4       4\n",
            "       ..\n",
            "1792    9\n",
            "1793    0\n",
            "1794    8\n",
            "1795    9\n",
            "1796    8\n",
            "Name: target, Length: 1797, dtype: int64\n",
            "(1797, 65)\n",
            "pixels          0    1     2     3     4     5  ...    59    60    61   62   63  target\n",
            "0     0.0  0.0   5.0  13.0   9.0   1.0  ...  13.0  10.0   0.0  0.0  0.0       0\n",
            "1     0.0  0.0   0.0  12.0  13.0   5.0  ...  11.0  16.0  10.0  0.0  0.0       1\n",
            "2     0.0  0.0   0.0   4.0  15.0  12.0  ...   3.0  11.0  16.0  9.0  0.0       2\n",
            "3     0.0  0.0   7.0  15.0  13.0   1.0  ...  13.0  13.0   9.0  0.0  0.0       3\n",
            "4     0.0  0.0   0.0   1.0  11.0   0.0  ...   2.0  16.0   4.0  0.0  0.0       4\n",
            "...   ...  ...   ...   ...   ...   ...  ...   ...   ...   ...  ...  ...     ...\n",
            "1792  0.0  0.0   4.0  10.0  13.0   6.0  ...  14.0  15.0   9.0  0.0  0.0       9\n",
            "1793  0.0  0.0   6.0  16.0  13.0  11.0  ...  16.0  14.0   6.0  0.0  0.0       0\n",
            "1794  0.0  0.0   1.0  11.0  15.0   1.0  ...   9.0  13.0   6.0  0.0  0.0       8\n",
            "1795  0.0  0.0   2.0  10.0   7.0   0.0  ...  12.0  16.0  12.0  0.0  0.0       9\n",
            "1796  0.0  0.0  10.0  14.0   8.0   1.0  ...  12.0  14.0  12.0  1.0  0.0       8\n",
            "\n",
            "[1797 rows x 65 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_RyRxRe9DFt"
      },
      "source": [
        "We are ready for splitting the given images in 80:20 ratio so that 80% image is available for training and 20 % image as unseen or unknown is available for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN-5qFmT9N4u",
        "outputId": "eeafed12-e43a-42ae-9b3d-584ee9cb3472"
      },
      "source": [
        "train_images, test_images, train_labels, test_labels = \\\n",
        "             train_test_split(pixels,labels,train_size=0.8,random_state=2);\n",
        "\n",
        "print('train size: ',len(train_images), len(train_labels))                \n",
        "print('test size: ',len(test_images), len(test_labels))  \n",
        " \n",
        "sclf.fit(train_images, train_labels)\n",
        "print('test score ',sclf.score(test_images,test_labels))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train size:  1437 1437\n",
            "test size:  360 360\n",
            "test score  0.9777777777777777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boVVaCiOBZMM"
      },
      "source": [
        "This gives us the score of 97 percent ( 0.977777 ) which is at all a good score. We would try to increase the accuracy but this is sort of challenge.\n",
        "\n",
        "The dataset description of our primer says: Each image is 8 pixels in height and 8 pixels in width, for a total of 64 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoueumYfBjED"
      },
      "source": [
        "Would be nice to get the confusion matrix of MNIST dataset to get an impression of the score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuMzk4hSBt3D",
        "outputId": "cc9896ee-a995-414f-856f-cc7ebde47ec0"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "test_predictions = sclf.predict(test_images)\n",
        "#print(confusion_matrix(test_labels,np.argmax(test_predictions,axis=1)))\n",
        "print(confusion_matrix(test_labels, test_predictions))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[32  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 44  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 31  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 36  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 32  0  0  1  2  0]\n",
            " [ 0  0  0  0  0 43  0  0  0  0]\n",
            " [ 0  1  0  0  0  0 34  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 40  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 34  2]\n",
            " [ 0  0  0  0  0  1  0  1  0 26]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs-0OgqgD7ic"
      },
      "source": [
        "Splitting the given images in 70:30 ratio shows a slight different confusion matrix so that 70% image is available for training and 30 % image as unseen or unknown is available for testing. Number 8 has probably most problems to get recognized! So disguise as 8 you can be a 6 or 9 and thats logical cause the 8 is in a 7-segment LCD display the base pattern! In german we say that with the word Achtung ;-)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ddeLNUMEVK-",
        "outputId": "be29a28c-2f39-4af2-947d-1a6a4f217cdd"
      },
      "source": [
        "train_images, test_images, train_labels, test_labels = \\\n",
        "             train_test_split(pixels,labels,train_size=0.7,random_state=2);\n",
        "\n",
        "sclf.fit(train_images, train_labels)\n",
        "print('test score ',sclf.score(test_images,test_labels))\n",
        "test_predictions = sclf.predict(test_images)\n",
        "print(confusion_matrix(test_labels, test_predictions))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test score  0.975925925925926\n",
            "[[54  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 56  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 54  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 60  0  2  0  0  0  0]\n",
            " [ 0  0  0  0 50  0  0  1  2  0]\n",
            " [ 0  0  0  0  0 58  0  0  0  1]\n",
            " [ 0  1  0  0  0  0 55  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 55  0  0]\n",
            " [ 0  2  0  0  0  0  1  0 43  1]\n",
            " [ 0  0  0  0  0  1  0  1  0 42]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}